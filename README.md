# Voice Cloning and Lip Synchronizer

## Mentors  
- **M Uzzwal**  
- **Rahul Bhimkari**  

## Mentees  
- **Aadharsh Ramachandran**  
- **Gauri Aggarwal**  
- **Parihasa K Reddy**  
- **Utkarsh Shukla**  

## ğŸ“Œ Aim  
The project aims to develop a system that generates **realistic speech through voice cloning** and **synchronizes lip movements** with minimal input data. This enables seamless dubbing, virtual avatars, and content creation.  

---

## ğŸ“– Introduction and Overview  
Voice cloning and lip synchronization play a crucial role in AI-driven **content creation, dubbing, and virtual avatars**.  

This project leverages:  
- **Tortoise TTS** for **zero-shot voice cloning**, requiring only **5-10 seconds** of speaker audio to generate realistic speech.  
- **Wav2Lip** to synchronize the generated voice with lip movements in videos, ensuring **natural and high-quality speech animation**.  

---

## ğŸ› ï¸ Technologies Used  

### **Voice Cloning**  
ğŸ”¹ **Tortoise TTS** â€“ Zero-shot voice cloning  

### **Lip Syncing**  
ğŸ”¹ **Wav2Lip** â€“ Modifies lip movements to match generated speech  

### **Frameworks & Libraries**  
ğŸ”¹ PyTorch  
ğŸ”¹ Gradio 
ğŸ”¹ FFmpeg  

### **Backend**  
ğŸ”¹ Flask â€“ Serving the application  

### **Evaluation Metrics**  
ğŸ”¹ **MOS (Mean Opinion Score)** â€“ Measures speech quality  
ğŸ”¹ **SyncNet Scores** â€“ Evaluates lip-sync accuracy  

---

## ğŸ“‚ Datasets  
- **Short audio clips (5-10 sec)** of different speakers for training/testing.  
- **Video samples** to evaluate lip-sync accuracy with cloned speech.  
- **Open-source datasets** for TTS and lip-syncing models (e.g., LRS2, VoxCeleb).  

---

## ğŸ—ï¸ Model and Architecture  

### **1ï¸âƒ£ Tortoise TTS**  
- Generates **high-quality, expressive speech** from limited data.  

### **2ï¸âƒ£ Wav2Lip**  
- Modifies **lip movements** to synchronize with the cloned voice.  

### **3ï¸âƒ£ Modular Deep Learning Pipeline**  
âœ” **Input audio processing**  
âœ” **TTS-based speech generation**  
âœ” **Lip-syncing using Wav2Lip**  
âœ” **Video output generation**  

---

## ğŸ¨ Gradio Interface  
ğŸ“ **Input**: Enter text for speech synthesis.  
ğŸ™ï¸ **Choose Speaker**: Select your preferred voice.  
ğŸ“º **Preview**: View the final synchronized video.  

---

## ğŸ¯ Conclusion  
This project successfully integrates **zero-shot voice cloning with lip synchronization**, producing **natural and expressive speech-driven animations**.  

âœ¨ It enhances:  
âœ… **AI-based dubbing**  
âœ… **Virtual avatars**  
âœ… **Personalized content creation**  

ğŸš€ Offering an innovative approach to **multimedia generation**!  
