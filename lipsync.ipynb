{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11215755,"sourceType":"datasetVersion","datasetId":7003773},{"sourceId":11216557,"sourceType":"datasetVersion","datasetId":6998090,"isSourceIdPinned":true}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**NEW FILE**","metadata":{}},{"cell_type":"code","source":"!pip install torchvision librosa==0.9.2 opencv-python-headless ffmpeg-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T06:53:16.706185Z","iopub.execute_input":"2025-04-01T06:53:16.706368Z","iopub.status.idle":"2025-04-01T06:53:21.925644Z","shell.execute_reply.started":"2025-04-01T06:53:16.706349Z","shell.execute_reply":"2025-04-01T06:53:21.924805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nimport torch\nfrom IPython.display import FileLink","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T06:54:25.42835Z","iopub.execute_input":"2025-04-01T06:54:25.428632Z","iopub.status.idle":"2025-04-01T06:54:28.530577Z","shell.execute_reply.started":"2025-04-01T06:54:25.428608Z","shell.execute_reply":"2025-04-01T06:54:28.529942Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"GPU Available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"CUDA Device:\", torch.cuda.get_device_name(0))\n    # Set device to GPU\n    device = torch.device(\"cuda\")\nelse:\n    print(\"No GPU available - using CPU\")\n    device = torch.device(\"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T06:54:31.23719Z","iopub.execute_input":"2025-04-01T06:54:31.23759Z","iopub.status.idle":"2025-04-01T06:54:31.348727Z","shell.execute_reply.started":"2025-04-01T06:54:31.237567Z","shell.execute_reply":"2025-04-01T06:54:31.348042Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Setup directory structure\nos.makedirs('checkpoints', exist_ok=True)\nos.makedirs('face_detection/detection/sfd', exist_ok=True)\nos.makedirs('results', exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T06:54:36.735295Z","iopub.execute_input":"2025-04-01T06:54:36.735582Z","iopub.status.idle":"2025-04-01T06:54:36.739783Z","shell.execute_reply.started":"2025-04-01T06:54:36.73556Z","shell.execute_reply":"2025-04-01T06:54:36.739134Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------------------------------------------\nface_video = \"/kaggle/input/audio-viddeo/trump2 - Made with Clipchamp.mp4\"  # Video with face\naudio_file = \"/kaggle/input/audio-viddeo/generated_speech2.wav\"  # Audio file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T06:54:40.431469Z","iopub.execute_input":"2025-04-01T06:54:40.431772Z","iopub.status.idle":"2025-04-01T06:54:40.435834Z","shell.execute_reply.started":"2025-04-01T06:54:40.431718Z","shell.execute_reply":"2025-04-01T06:54:40.434712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocessed_video = \"preprocessed_face2.mp4\"\n!ffmpeg -i \"{face_video}\" -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p -strict -2 \"{preprocessed_video}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T06:54:43.647139Z","iopub.execute_input":"2025-04-01T06:54:43.647411Z","iopub.status.idle":"2025-04-01T06:54:54.89527Z","shell.execute_reply.started":"2025-04-01T06:54:43.64739Z","shell.execute_reply":"2025-04-01T06:54:54.894401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Create the temp directory if it doesn't exist\nos.makedirs(\"temp\", exist_ok=True)\nos.makedirs(\"results\", exist_ok=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T06:54:54.89649Z","iopub.execute_input":"2025-04-01T06:54:54.896799Z","iopub.status.idle":"2025-04-01T06:54:54.901103Z","shell.execute_reply.started":"2025-04-01T06:54:54.896771Z","shell.execute_reply":"2025-04-01T06:54:54.90026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"os.makedirs(\"temp\", exist_ok=True)\nos.makedirs(\"results\", exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:00:54.176602Z","iopub.execute_input":"2025-04-01T07:00:54.176928Z","iopub.status.idle":"2025-04-01T07:00:54.181Z","shell.execute_reply.started":"2025-04-01T07:00:54.176904Z","shell.execute_reply":"2025-04-01T07:00:54.180009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nprint(\"Preprocessed video exists:\", os.path.exists(\"preprocessed_face2.mp4\"))\nprint(\"Audio file exists:\", os.path.exists(audio_file))\nprint(\"Checkpoint exists:\", os.path.exists(\"/kaggle/input/wav2lip/Wav2Lip/checkpoints/wav2lip_gan.pth\"))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:00:25.775298Z","iopub.execute_input":"2025-04-01T07:00:25.775569Z","iopub.status.idle":"2025-04-01T07:00:25.781996Z","shell.execute_reply.started":"2025-04-01T07:00:25.775548Z","shell.execute_reply":"2025-04-01T07:00:25.781158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python /kaggle/input/wav2lip/Wav2Lip/inference.py \\\n--checkpoint_path /kaggle/input/wav2lip/Wav2Lip/checkpoints/wav2lip_gan.pth \\\n--face \"{preprocessed_video}\" \\\n--audio \"{audio_file}\" \\\n--outfile temp/result3.avi \\\n--resize_factor 1 \\\n--fps 25 \\\n--face_det_batch_size 4 \\\n--wav2lip_batch_size 16 \\\n--nosmooth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:01:37.320292Z","iopub.execute_input":"2025-04-01T07:01:37.320588Z","iopub.status.idle":"2025-04-01T07:05:15.675125Z","shell.execute_reply.started":"2025-04-01T07:01:37.320565Z","shell.execute_reply":"2025-04-01T07:05:15.674054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!ffmpeg -i temp/result3.avi -vcodec libx264 -acodec aac results/result3.mp4\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:05:21.113622Z","iopub.execute_input":"2025-04-01T07:05:21.113963Z","iopub.status.idle":"2025-04-01T07:05:34.376703Z","shell.execute_reply.started":"2025-04-01T07:05:21.113934Z","shell.execute_reply":"2025-04-01T07:05:34.375829Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if os.path.exists(\"results/result3.mp4\"):\n    print(\"Lip-synced video generated successfully!\")\n    display(FileLink(\"results/result3.mp4\"))\nelse:\n    raise FileNotFoundError(\"Output video was not generated. Check logs for errors.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T07:06:03.750295Z","iopub.execute_input":"2025-04-01T07:06:03.750693Z","iopub.status.idle":"2025-04-01T07:06:03.758198Z","shell.execute_reply.started":"2025-04-01T07:06:03.750659Z","shell.execute_reply":"2025-04-01T07:06:03.757373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install dependencies\n!pip install torchvision librosa==0.9.2 opencv-python-headless ffmpeg-python gradio torchaudio tortoise-tts ffmpeg-python\n\nimport os\nimport torch\nimport torchaudio\nimport gradio as gr\nimport subprocess\nimport shutil\nfrom tortoise.api import TextToSpeech\nfrom tortoise.utils.audio import load_audio\n\n# Constants\nWORKING_DIR = \"/kaggle/working/\"\nCLONED_VOICE_PATH = os.path.join(WORKING_DIR, \"cloned_voice1.wav\")\nOUTPUT_VIDEO_PATH = os.path.join(WORKING_DIR, \"lip_sync_result1.mp4\")\n\n# Setup directories\nos.makedirs(WORKING_DIR, exist_ok=True)\nos.makedirs(os.path.join(WORKING_DIR, \"temp\"), exist_ok=True)\n\n# Initialize TTS\ntts = TextToSpeech()\n\ndef generate_voice_clone(audio_file, text, quality):\n    \"\"\"Generate cloned voice and save to fixed location\"\"\"\n    try:\n        # Handle Gradio audio input\n        if isinstance(audio_file, tuple):\n            sample_rate, audio_data = audio_file\n            torchaudio.save(CLONED_VOICE_PATH, torch.from_numpy(audio_data).float(), sample_rate)\n        else:\n            shutil.copy(audio_file, CLONED_VOICE_PATH)\n        \n        # Generate cloned voice\n        voice_samples = [load_audio(CLONED_VOICE_PATH, 22050)]\n        gen = tts.tts_with_preset(\n            text,\n            voice_samples=voice_samples,\n            preset=quality,\n            diffusion_iterations=100\n        )\n        \n        # Save the final output\n        torchaudio.save(CLONED_VOICE_PATH, gen.squeeze(0).cpu(), 24000)\n        \n        return CLONED_VOICE_PATH, \"Voice cloned successfully!\"\n        \n    except Exception as e:\n        return None, f\"Error: {str(e)}\"\n\ndef lip_sync(video_path):\n    \"\"\"Lip-sync using the pre-generated voice with proper preprocessing\"\"\"\n    try:\n        if not os.path.exists(CLONED_VOICE_PATH):\n            return None, \"Please generate voice clone first!\"\n        \n        # Handle video input\n        if isinstance(video_path, dict):\n            video_path = video_path[\"name\"]\n        elif isinstance(video_path, tuple):\n            video_path = video_path[1]\n        \n        # Create directories\n        temp_dir = os.path.join(WORKING_DIR, \"temp\")\n        results_dir = os.path.join(WORKING_DIR, \"results\")\n        os.makedirs(temp_dir, exist_ok=True)\n        os.makedirs(results_dir, exist_ok=True)\n        \n        # Prepare paths\n        processed_video_path = os.path.join(temp_dir, \"preprocessed_input.mp4\")\n        temp_audio_path = os.path.join(temp_dir, \"audio.wav\")\n        temp_output_path = os.path.join(temp_dir, \"result.avi\")\n        final_output_path = os.path.join(results_dir, \"lip_sync_output.mp4\")\n        \n        # Convert audio to 16000Hz\n        cmd = f\"ffmpeg -y -i {CLONED_VOICE_PATH} -ar 16000 {temp_audio_path}\"\n        subprocess.run(cmd, shell=True, check=True)\n        \n        # Preprocess video (critical step!)\n        cmd = f'ffmpeg -y -i \"{video_path}\" -c:v libx264 -profile:v high -crf 20 -pix_fmt yuv420p -strict -2 \"{processed_video_path}\"'\n        subprocess.run(cmd, shell=True, check=True)\n        \n        # Run Wav2Lip with parameters matching the working version\n        cmd = f\"\"\"\n        python /kaggle/input/wav2lip/Wav2Lip/inference.py \\\n        --checkpoint_path /kaggle/input/wav2lip/Wav2Lip/checkpoints/wav2lip_gan.pth \\\n        --face \"{processed_video_path}\" \\\n        --audio \"{temp_audio_path}\" \\\n        --outfile \"{temp_output_path}\" \\\n        --resize_factor 1 \\\n        --fps 25 \\\n        --face_det_batch_size 4 \\\n        --wav2lip_batch_size 16 \\\n        --nosmooth\n        \"\"\"\n        subprocess.run(cmd, shell=True, check=True)\n        \n        # Convert output to MP4\n        cmd = f'ffmpeg -y -i \"{temp_output_path}\" -vcodec libx264 -acodec aac \"{final_output_path}\"'\n        subprocess.run(cmd, shell=True, check=True)\n        \n        if os.path.exists(final_output_path):\n            return final_output_path, \"Lip-sync complete!\", CLONED_VOICE_PATH\n        else:\n            return None, \"Lip-sync failed - no output generated\", None\n            \n    except subprocess.CalledProcessError as e:\n        return None, f\"Command failed: {e.cmd} with return code {e.returncode}\", None\n    except Exception as e:\n        return None, f\"Error: {str(e)}\", None\n \n\n\n# Custom CSS for styling\n\n\n# Custom CSS with improved visibility and modern colors\n\n# Custom CSS with dark theme\ncustom_css = \"\"\"\n.gradio-container {\n    font-family: 'Helvetica', Arial, sans-serif;\n    background: #000000 !important;\n    color: #ffffff !important;\n}\n.header {\n    text-align: center;\n    margin-bottom: 20px;\n    padding: 20px;\n    background: #1a1a1a !important;\n    border-radius: 12px;\n    box-shadow: 0 4px 6px rgba(0,0,0,0.3);\n}\n.header h1 {\n    color: #ffffff !important;\n    margin-bottom: 10px;\n    font-weight: 700;\n}\n.header p {\n    color: #b3b3b3 !important;\n    font-size: 1.1em;\n}\n.tab {\n    background: #2d2d2d !important;\n    border-radius: 12px;\n    padding: 20px;\n    box-shadow: 0 4px 12px rgba(0,0,0,0.3);\n    border: 1px solid #404040 !important;\n    color: #ffffff !important;\n}\n.input-section, .output-section {\n    background: #3d3d3d !important;\n    border-radius: 12px;\n    padding: 20px;\n    margin-bottom: 20px;\n    box-shadow: 0 2px 8px rgba(0,0,0,0.3);\n    border: 1px solid #505050 !important;\n    color: #ffffff !important;\n}\n.input-section h2, .output-section h2 {\n    color: #ffffff !important;\n    margin-top: 0;\n    padding-bottom: 12px;\n    border-bottom: 2px solid #505050 !important;\n    font-weight: 600;\n}\n.btn {\n    background: linear-gradient(135deg, #4a6baf 0%, #3a5a9f 100%) !important;\n    color: white !important;\n    border: none !important;\n    padding: 12px 24px !important;\n    border-radius: 8px !important;\n    font-weight: 600 !important;\n    box-shadow: 0 2px 4px rgba(0,0,0,0.3) !important;\n    transition: all 0.3s ease !important;\n}\n.btn:hover {\n    transform: translateY(-2px) !important;\n    box-shadow: 0 4px 8px rgba(0,0,0,0.4) !important;\n    background: linear-gradient(135deg, #3a5a9f 0%, #2a4a8f 100%) !important;\n}\n.status-box {\n    background: #2d2d2d !important;\n    padding: 12px;\n    border-radius: 8px;\n    border-left: 4px solid #4a6baf !important;\n    font-family: monospace;\n    color: #ffffff !important;\n}\nlabel {\n    font-weight: 500 !important;\n    color: #cccccc !important;\n    margin-bottom: 8px !important;\n}\n.gr-interface {\n    background: transparent !important;\n}\n.tabs {\n    gap: 16px !important;\n}\n.gr-box {\n    border-color: #505050 !important;\n    background: #3d3d3d !important;\n    color: white !important;\n}\ninput, textarea, select {\n    background: #2d2d2d !important;\n    color: white !important;\n    border-color: #505050 !important;\n}\n\"\"\"\n\n# Gradio Interface with dark theme\nwith gr.Blocks(css=custom_css, theme=gr.themes.Default(primary_hue=\"blue\")) as app:\n    with gr.Column():\n        gr.Markdown(\"\"\"\n        <div class=\"header\">\n            <h1>🎤 AI Voice Cloning + 🎬 Lip Sync Studio</h1>\n            <p>Transform any voice and create perfectly synced videos with cutting-edge AI</p>\n        </div>\n        \"\"\")\n    \n    with gr.Tabs():\n        with gr.Tab(\"1. Voice Cloning\", elem_classes=\"tab\"):\n            with gr.Row(equal_height=True):\n                with gr.Column(scale=1, elem_classes=\"input-section\"):\n                    gr.Markdown(\"### 🛠️ Input Parameters\")\n                    audio_input = gr.Audio(label=\"🎙️ Reference Voice Sample\", \n                                         type=\"filepath\",\n                                         elem_id=\"audio-input\")\n                    text_input = gr.Textbox(label=\"📝 Text to Speak\", \n                                           placeholder=\"Type what you want the cloned voice to say...\",\n                                           lines=3)\n                    quality = gr.Dropdown(\n                        label=\"⚡ Quality Preset\", \n                        choices=[\"fast\", \"standard\", \"high_quality\"], \n                        value=\"standard\",\n                        info=\"Higher quality = better results but longer processing\"\n                    )\n                    clone_btn = gr.Button(\"✨ Generate Cloned Voice\", elem_classes=\"btn\")\n                \n                with gr.Column(scale=1, elem_classes=\"output-section\"):\n                    gr.Markdown(\"### 🎧 Results\")\n                    voice_output = gr.Audio(label=\"🔊 Cloned Voice Output\", \n                                           interactive=False,\n                                           elem_id=\"audio-output\")\n                    with gr.Group():\n                        gr.Markdown(\"**📊 Status**\")\n                        clone_status = gr.Textbox(label=\"\", \n                                                show_label=False, \n                                                elem_classes=\"status-box\",\n                                                placeholder=\"Waiting for voice generation...\")\n        \n        with gr.Tab(\"2. Lip Sync\", elem_classes=\"tab\"):\n            with gr.Row(equal_height=True):\n                with gr.Column(scale=1, elem_classes=\"input-section\"):\n                    gr.Markdown(\"### 🎥 Video Input\")\n                    video_input = gr.Video(label=\"📽️ Upload Target Video\", \n                                         elem_id=\"video-input\")\n                    sync_btn = gr.Button(\"🎬 Generate Lip Sync\", elem_classes=\"btn\")\n                    gr.Markdown(\"\"\"\n                    <div style=\"color: #b3b3b3; font-size: 0.9em; margin-top: 10px;\">\n                    ℹ️ You must generate a voice clone in the first tab before lip-syncing.\n                    </div>\n                    \"\"\")\n                \n                with gr.Column(scale=1, elem_classes=\"output-section\"):\n                    gr.Markdown(\"### 🎞️ Final Output\")\n                    video_output = gr.Video(label=\"📺 Lip-Synced Video\", \n                                         elem_id=\"video-output\")\n                    with gr.Group():\n                        gr.Markdown(\"**📊 Status**\")\n                        sync_status = gr.Textbox(label=\"\", \n                                               show_label=False, \n                                               elem_classes=\"status-box\",\n                                               placeholder=\"Waiting for lip sync...\")\n                    voice_review = gr.Audio(label=\"🔈 Voice Used for Lip Sync\", \n                                          interactive=False)\n    \n    # Voice cloning action\n    clone_btn.click(\n        fn=generate_voice_clone,\n        inputs=[audio_input, text_input, quality],\n        outputs=[voice_output, clone_status]\n    )\n    \n    # Lip-sync action\n    sync_btn.click(\n        fn=lip_sync,\n        inputs=[video_input],\n        outputs=[video_output, sync_status, voice_review]\n    )\n\napp.launch(share=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T14:36:44.701818Z","iopub.execute_input":"2025-04-01T14:36:44.702249Z","iopub.status.idle":"2025-04-01T14:37:07.007956Z","shell.execute_reply.started":"2025-04-01T14:36:44.702218Z","shell.execute_reply":"2025-04-01T14:37:07.007027Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}